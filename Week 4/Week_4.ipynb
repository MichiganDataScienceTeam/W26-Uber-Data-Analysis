{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import the relevant libraries and load in the csv file (be sure to upload it in the files section!)."
      ],
      "metadata": {
        "id": "Lev4lENvGvoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import f_oneway\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "df = pd.read_csv('UberDataset Current.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "VxG3qHGLG23X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a filtered dataframe based on whether you are in the Business Category or Personal Category group, and use this dataframe accordingly in the rest of the module:**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "USfAb9niL4W4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#business or personal"
      ],
      "metadata": {
        "id": "2Kl6PeYmL63l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Let's do a little bit of data cleaning! CURRENTLY the \"Top 5 Most Frequent Routes\" are:\n",
        "\n",
        "NO_DATA -> NO_DATA     86\n",
        "\n",
        "Morrisville -> Cary    75\n",
        "\n",
        "Cary -> Morrisville    67\n",
        "\n",
        "Cary -> Cary           53\n",
        "\n",
        "Cary -> Durham         36\n",
        "\n",
        "We don't want [no route -> no route] produced, so let's exclude this from the output of \"Top 5 Most Frequent Routes\":\n",
        "* Remember to format the output as (start) -> (stop)\n",
        "* Don't directly change the dataframe"
      ],
      "metadata": {
        "id": "mGq5MS7yLuAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#business or personal"
      ],
      "metadata": {
        "id": "Q9UDufRHLydQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Find the demand (number of rides per hour), and segment it by\n",
        "* hour\n",
        "* day_of_week\n",
        "* is_rush_hour"
      ],
      "metadata": {
        "id": "0yW9NVBLMBkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print it at end"
      ],
      "metadata": {
        "id": "I5U8vdWgMHFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Using scipy's T-test function, compare rush vs non-rush demand by the hour."
      ],
      "metadata": {
        "id": "Dc9UkRFrG5g6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Ensure START_DATE is in datetime format for time-based grouping\n",
        "\n",
        "# 2. Create a 'hour_bucket' column\n",
        "# Use .dt.floor.('h')\n",
        "\n",
        "# 3. Aggregate data to get demand (rides count) per hour bucket\n",
        "# We also preserve the 'is_rush_hour' status for that hour\n",
        "\n",
        "# 4. Separate the demand into Rush and Non-Rush groups (create Series)\n",
        "\n",
        "# 5. Perform the T-test (remember, it returns 2 things)\n",
        "\n",
        "# 6. Display Results for rush hour mean, non-rush hour mean, p-value, and t-statistic\n",
        "\n",
        "# 7. Determine if there is a singificant different (metric: < 0.05)"
      ],
      "metadata": {
        "id": "agTlqkBo6n3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Day of week analysis to test whether average demand differs by day: ANOVA updates"
      ],
      "metadata": {
        "id": "Fnnu0TITM0e2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Return a sub-dataframe: daily_hourly_demand\n",
        "# Remember, we are grouping by hour_bucket (which rounds down to nearest hour)\n",
        "# So, aggregate to create rides_count column (where we want number of rides in each hour_bucket)\n",
        "# And, aggregate based on day_of_week (we just need first day value within hour bucket group, since they are all on the same day)\n",
        "\n",
        "# 2. Prepare data: Create a list of hourly ride counts for each day (0=Mon, 6=Sun)\n",
        "# Create a list of the unique days\n",
        "\n",
        "# Create a list of groups of ride counts of each hour bucket per day\n",
        "\n",
        "\n",
        "# 3. ANOVA (expects multiple entries in parameter, can use (*<list>) syntax to represent the multiple entires)\n",
        "\n",
        "# 4. print whether p-value is significant or not\n"
      ],
      "metadata": {
        "id": "6ToBD0z8M4Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confidence intervals (answer the overarching question)"
      ],
      "metadata": {
        "id": "Ol8Igr6PNDv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pick a time and day and create a series (look into dataset to make sure there is more than ONE observation)\n",
        "\n",
        "# make mean and sem variables\n",
        "\n",
        "\n",
        "# make ci and print mean demand and ci\n"
      ],
      "metadata": {
        "id": "vL8hVPxxNHSu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}