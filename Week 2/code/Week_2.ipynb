{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Import the relevant libraries."
      ],
      "metadata": {
        "id": "zMp3ZKmhW92U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Load the \"corrupted\" dataset. Make sure to run methods like .head() and .info() to make sure it was loaded properly!"
      ],
      "metadata": {
        "id": "CWKwMVkdXeQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Iterate through all dataframe columns to check for NaN (empty) cells. If you find one, override the cell with '**NO_DATA**'."
      ],
      "metadata": {
        "id": "oZdjWdAEYH_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Focus at the START and STOP columns. Scroll around a bit and find the typos. Make a custom pattern that can be used for both typo formats. **OVERRIDE** the previous cell.\n",
        "\n",
        "The correct words should be: Rawalpindi and Karachi.\n",
        "\n",
        "Hint: use r'STRING' (raw) for your pattern, and use .findall(pattern, string)."
      ],
      "metadata": {
        "id": "mf4MhzKNaNX9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Override all 'Unknown Location' values to 'NO_DATA'\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aud8COPYkTW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Convert all the START_DATE and END_DATE values to datetime objects."
      ],
      "metadata": {
        "id": "Ph2ibCzGkuTm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Create a function that validate that timings for the trip makes sense (start date should be less than end date), and if not, sets both START_DATE and END_DATE to NaT\n",
        "\n"
      ],
      "metadata": {
        "id": "bxX23sAqwtNS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Extract these specific time features: hour, day of the week, if it is rush hour (let rush hour be between 7-9 am and 4-6 pm), and if it is the weekend (based on START_DATE column)"
      ],
      "metadata": {
        "id": "TBcgIUWwsvWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "Lic_1BT6qWon"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Connect to our **GitHub**. The API data is divided up into hourly segments. Using both the **START** location and the **START_DATE**, as well as the datetime attributes, make a web request for each of your rows.\n",
        "\n",
        "Hintï¼šFind & get the corresponding index in the hourly list, then use that to get the other attributes.\n",
        "\n",
        "PLEASE CACHE YOUR DATA TO AVOID BURNING THE SERVER.\n",
        "\n"
      ],
      "metadata": {
        "id": "eZ8JHcT5mxo-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Prep the DataFrame so that it would be ready for modeling (don't worry, we won't start modeling just yet!):\n",
        "\n",
        "a) keep only numeric columns (in a copy)\n",
        "\n",
        "b) fill in Na values with the group-wise mean for each START location if applicable\n",
        "\n",
        "c) create these interaction features:\n",
        "  - Temperature x Wind Speed (Low temp AND high winds = awful combo, high temp AND high winds = good combo)\n",
        "  - Overall Weather Stress (Hint: summation)"
      ],
      "metadata": {
        "id": "5BP6L1jx0ENz"
      }
    }
  ]
}
